This project demonstrates a real-time data pipeline built using Spring Boot, Apache Kafka, and PostgreSQL.

It streams live edit events from Wikimedia‚Äôs public EventStream API (https://stream.wikimedia.org/v2/stream/recentchange), produces them to a Kafka topic, and consumes them in another Spring Boot service which stores the data in a PostgreSQL database.

This project shows how to:

Build a Kafka Producer with Spring Boot.

Consume real-time Kafka messages.

Persist messages into PostgreSQL in real-time.

Handle long-lived event streams efficiently.

üèóÔ∏è Project Architecture
          +-----------------------------+
          | Wikimedia Event Stream API  |
          | (Real-time JSON changes)    |
          +--------------+--------------+
                         |
                         ‚ñº
              [Spring Boot Kafka Producer]
                         |
                         ‚ñº
                 +----------------+
                 | Kafka Topic    |
                 | wikimedia_recentchange |
                 +----------------+
                         |
                         ‚ñº
              [Spring Boot Kafka Consumer]
                         |
                         ‚ñº
                 +----------------+
                 | PostgreSQL DB  |
                 | wikimedia_data |
                 +----------------+

‚öôÔ∏è Tech Stack
Component	Technology
Language	Java 21
Framework	Spring Boot 3.x
Messaging System	Apache Kafka
Database	PostgreSQL
Dependency Management	Maven
Streaming Library	okhttp-eventsource 2.5.0
Build Tool	Maven
IDE	IntelliJ / Eclipse


üß© Kafka Setup (Windows Example)

1Ô∏è‚É£ Download latest version of apache-kafka


2Ô∏è‚É£ Start Kafka Broker

bin\windows\kafka-server-start.bat config\server.properties  (change dir to kafka installtion folder)


3Ô∏è‚É£ Create Topic

bin\windows\kafka-topics.bat --create --topic wikimedia_recentchange --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1


4Ô∏è‚É£ Verify Topic

bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092

# Understanding the Flow ##

Producer uses LaunchDarkly‚Äôs EventSource to connect to Wikimedia‚Äôs SSE stream.

Each JSON message is pushed into a Kafka topic (wikimedia_recentchange).

Consumer listens to that topic using @KafkaListener.

Messages are parsed and stored into PostgreSQL in real-time.
